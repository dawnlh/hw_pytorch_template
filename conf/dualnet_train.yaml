##### hydra
hydra:
    run:
      dir: ./outputs/${exp_name}/${status}/${now:%Y-%m-%d}_${now:%H-%M-%S}
    sweep:
      dir: ./outputs/${exp_name}/${status}/${now:%Y-%m-%d}_${now:%H-%M-%S}
      subdir: ${hydra.job.override_dirname}

##### dir
exp_name: code_dev/dualnet  # experiment name
trainer_name: dualnet_trainer # trainer name
status: train       # run status: train|test|debug
resume_conf: [] # resume configuration, default=[epoch, optimizer]
resume_a:  # resuming checkpoint path (${hydra:runtime.cwd}/ )
resume_b: # resuming checkpoint path (${hydra:runtime.cwd}/ )
checkpoint_dir: checkpoints/   # models saving dir (relative to $dir)
final_test_dir: final_test/    # final test result saving dir (relative to $dir)
log_dir: events/   # log file save dir (relative to $dir)
# outputs_dir:

##### run
gpus: [4]                 # GPU used, [0,1] | empty (all gpu)
num_workers: 16            # number of cpu worker
trainer:
  workflow: [{mode: alter, n: 20, op: [[a, 5], [b, 5]]}, {mode: e2e, n: 200}]
  # workflow: [{mode: alter, n: 1, op: [[a, 400]]}]
  init_epochs: {a: 0, b: 0} # initlization epoch
  limit_train_iters:    # maximal trainning batches: empty for all
  limit_valid_iters:      # maximal validation batches: empty for all
  saving_latest_k: 5      # save top k checkpoints (best checkpoints saved separately)
  logging_step: 400       # one log / $logging_step iteration
  tensorboard: true       # use tensorboard for training log



##### metrics
metrics_a:
  - _target_: srcs.metric.metric.calc_mse
metrics_b:
  - _target_: srcs.metric.metric.calc_psnr
  - _target_: srcs.metric.metric.calc_ssim

##### data&nets
defaults:
  - data: _my_train_data
  - network: dualnet
  - hparams: ced_hyparams

  - override hydra/job_logging : custom # custom || colorlog
  - override hydra/hydra_logging: colorlog
  - _self_
